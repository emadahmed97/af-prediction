import os
from keras.layers import Conv1D, MaxPooling1D, \
                         BatchNormalization, Activation
from cardio.dataset.models.keras import KerasModel
from keras.layers import Input, Flatten, Dense, GlobalMaxPooling1D
from cardio.dataset import F
from cardio.dataset import Pipeline, V
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import classification_report
from cardio import EcgDataset
import cardio.dataset as ds
import numpy as np

AF_SIGNALS_PATH = 'cardio/tests/data/training2017/' #set path to the PhysioNet database
AF_SIGNALS_MASK = os.path.join(AF_SIGNALS_PATH, "*.hea")
AF_SIGNALS_REF = os.path.join(AF_SIGNALS_PATH, "REFERENCE.csv")

afds = EcgDataset(path=AF_SIGNALS_MASK, no_ext=True, sort=True)

afds.cv_split(0.8)

preprocess_pipeline = (ds.Pipeline()
                       .load(fmt="wfdb", components=["signal", "meta"])
                       .load(src=AF_SIGNALS_REF, fmt="csv", components="target")
                       .drop_labels(["~"])
                       .rename_labels({"N": "NO", "O": "NO"})

                       .drop_short_signals(4000)
                       .random_split_signals(3000, 3)
                       .apply_transform(func=np.transpose, src='signal', dst='signal', axes=[0, 2, 1]))


def keras_conv_block(input_layer, nb_filters):
    conv = Conv1D(nb_filters, 4)(input_layer)
    bnorm = BatchNormalization(momentum=0.9)(conv)
    relu = Activation('relu')(bnorm)
    output = MaxPooling1D()(relu)
    return output

class KerasConvModel(KerasModel):
    def _build(self, **kwargs):
        x = Input(kwargs['input_shape'])
        conv = x
        for nb_filters in kwargs['filters']:
            conv = keras_conv_block(conv, nb_filters)
        flat = GlobalMaxPooling1D()(conv)
        output = Dense(2, activation='softmax')(flat)
        return x, output

model_config = {
    "input_shape": F(lambda batch: batch.signal[0].shape[1:]),
    "loss": "binary_crossentropy",
    "optimizer": "adam",
    'filters': [4, 4, 8, 8, 16, 16, 32, 32]
}

def make_signals(batch):
    return np.array([segment for signal in batch.signal for segment in signal])

def make_targets(batch):
    n_reps = [signal.shape[0] for signal in batch.signal]
    return np.repeat(batch.target, n_reps, axis=0)

def keras_make_data(batch, **kwagrs):
    if any(elem is None for elem in batch.target):
        return {'x': make_signals(batch)}
    else:
        return {'x': make_signals(batch), 'y': make_targets(batch)}

with Pipeline() as p:
    keras_train_pipeline = (p.init_model("dynamic", KerasConvModel, name="conv_model", config=model_config)
                            +
                            p.init_variable("loss_history", init_on_each_run=list)
                            +
                            preprocess_pipeline
                            +
                            p.binarize_labels()
                            +
                            p.train_model('conv_model', make_data=keras_make_data,
                                          save_to=V("loss_history"), mode="a"))

keras_model_trained = (afds.train >> keras_train_pipeline).run(batch_size=256, n_epochs=150, shuffle=True,
                                                                   drop_last=True)

plt.plot(keras_model_trained.get_variable("loss_history"))
plt.xlabel("Iteration")
plt.ylabel("Training loss")
plt.show()

keras_predict_pipeline = (ds.Pipeline()
                          .import_model("conv_model", keras_model_trained)
                          .init_variable("predictions_list", init_on_each_run=list)
                          .load(fmt="wfdb", components=["signal", "meta"])
                          .random_split_signals(3000, 1)
                          .apply_transform(func=np.transpose, src='signal', dst='signal', axes=[0, 2, 1])
                          .predict_model('conv_model', make_data=keras_make_data,
                                         save_to=V("predictions_list"), mode="e"))

keras_res = (afds.test >> keras_predict_pipeline).run(batch_size=len(afds.test.indices),
                                                      n_epochs=1, shuffle=False, drop_last=False)

pd.options.display.float_format = '{:.2f}'.format

pred_proba = pd.DataFrame([x[0] for x in keras_res.get_variable("predictions_list")],
                    index=afds.test.indices, columns=['AF prob'])

true_labels = (pd.read_csv(AF_SIGNALS_REF, index_col=0, names=['True label'])
               .replace(['N', 'O', '~'], 'NO'))

df = pd.merge(pred_proba, true_labels, how='left', left_index=True, right_index=True)
df.head(10)

print(classification_report((df['True label'] == 'A').astype(int),
                            (df['AF prob'].astype(float) >= 0.5).astype(int),
                            target_names = ['NO', 'A']))